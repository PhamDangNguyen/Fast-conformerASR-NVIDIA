{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc hết data đã có trong năm 2023 và nửa đầu năm 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "root_folder_metadata = \"/mnt/driver/STT_data/STT_dataset/57.1_metadata_56_54.../total_csv\"\n",
    "dfs = []\n",
    "for csv_file in list(Path(root_folder_metadata).rglob(\"*_val.csv\")):\n",
    "    dfs.append(pd.read_csv(csv_file))\n",
    "df_concat_57csv = pd.concat(dfs)\n",
    "df_concat_57csv.to_csv('/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/val.csv', index=False, encoding='utf-8')\n",
    "# df_concat_57csv = pd.read_csv(\"/mnt/driver/STT_data/STT_dataset/57.1_metadata_56_54.../57_exits.csv\")\n",
    "\n",
    "# columns_to_save = [\"file\", \"text\", \"duration\"]\n",
    "# df_concat_57csv.to_csv('/home/pdnguyen/fast_confomer_finetun/CSV_process_data/data_extral_t6.csv', columns=columns_to_save, index=False, encoding='utf-8')\n",
    "# df_train = df_train[(df_train[\"duration\"] > 1) & (df_train[\"duration\"] < 20)]\n",
    "# df_train[\"file\"] = df_train[\"file\"].apply(lambda x: x.replace(\"/home/ndanh/STT_dataset\", \"/home/ntdong/Data/STT_dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to: /home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/stt_concat.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_and_save(csv_file, output_file_filtered, output_file_remaining):\n",
    "    # Đọc dữ liệu từ file CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Lọc các hàng có chứa \"augment\", \"noise\", hoặc \"bg\" trong cột 'file'\n",
    "    filtered_df = df[df['file'].str.contains('31.concat_stt_2_persons', case=False, na=False)]\n",
    "    \n",
    "    # Lọc các hàng không chứa \"augment\", \"noise\", hoặc \"bg\"\n",
    "    # remaining_df = df[~df['file'].str.contains('augment|noise|bg|bg_noise|white|dns48|short|compression|mp3|new_bg|63.Augment_speed_lound|61.Augment2same_telesales', case=False, na=False)]\n",
    "    \n",
    "    # Lưu DataFrame đã lọc vào một file CSV khác\n",
    "    filtered_df.to_csv(output_file_filtered, index=False)\n",
    "    \n",
    "    # Lưu DataFrame còn lại vào một file CSV khác\n",
    "    # remaining_df.to_csv(output_file_remaining, index=False)\n",
    "\n",
    "# Đường dẫn tới file CSV ban đầu\n",
    "input_file = \"/mnt/driver/STT_data/STT_dataset/57.1_metadata_56_54.../57_exits.csv\"\n",
    "\n",
    "# Đường dẫn tới file CSV để lưu kết quả đã lọc\n",
    "output_file_filtered = \"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/stt_concat.csv\"\n",
    "\n",
    "# Đường dẫn tới file CSV để lưu kết quả còn lại\n",
    "# output_file_remaining = \"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/bo_di.csv\"\n",
    "\n",
    "# Gọi hàm để thực hiện lọc và lưu file\n",
    "filter_and_save(input_file, output_file_filtered, output_file_remaining = None)\n",
    "\n",
    "print(f\"Filtered data has been saved to: {output_file_filtered}\")\n",
    "# print(f\"Remaining data has been saved to: {output_file_remaining}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2677.0982122916685\n"
     ]
    }
   ],
   "source": [
    "print(df_concat_57csv[\"duration\"].sum()/3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Làm data cho mnt/driver + Convert CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Làm csv tổng cho tiktok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "root_folder_metadata = \"/mnt/driver/STT_data/STT_dataset/65.Tiktok_T7\"\n",
    "dfs = []\n",
    "for csv_file in list(Path(root_folder_metadata).rglob(\"*.csv\")):\n",
    "    csv_file_str = str(csv_file).split(\"/final_label.csv\")[0]\n",
    "    print(csv_file_str)\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"file\"] = df[\"file\"].apply(lambda x: x.replace(\"audio_processed\",f\"{csv_file_str}/audio_processed\"))\n",
    "    dfs.append(df)\n",
    "\n",
    "df_concat_65csv = pd.concat(dfs)\n",
    "# print(df_concat_57csv[\"duration\"].sum()/3600)\n",
    "\n",
    "columns_to_save = [\"file\", \"text\", \"duration\"]\n",
    "df_concat_65csv.to_csv('/home/pdnguyen/fast_confomer_finetun/CSV_process_data/Tiktokdata_extral_t7.csv', columns=columns_to_save, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_65csv[\"duration\"].sum()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "metadata_57 = pd.read_csv(\"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/57_exits.csv\")\n",
    "metadata_64 = pd.read_csv(\"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/64.Metadata_t6__exits.csv\")\n",
    "metadata_telethem = pd.read_csv(\"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/metadata_train_tele_them_7_5_2024.csv\")\n",
    "metadata_tiktok = pd.read_csv(\"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/Tiktokdata_extral_t7_exist.csv\")\n",
    "vlsp_test1 = pd.read_csv(\"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/vlsp_2020_test_task1.csv\")\n",
    "vlsp_test1['duration'] = 5\n",
    "vlsp_test2 = pd.read_csv(\"/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/vlsp_2020_test_task2.csv\")\n",
    "vlsp_test2['duration'] = 5\n",
    "print(vlsp_test2.shape)\n",
    "dfs = [metadata_57,metadata_64,metadata_telethem,metadata_tiktok,vlsp_test1,vlsp_test2]\n",
    "\n",
    "# # Đọc tất cả các tệp .csv trong thư mục và các thư mục con\n",
    "# for csv_file in list(Path(root_folder_metadata).rglob(\"*.csv\")):\n",
    "#     df = pd.read_csv(csv_file)\n",
    "#     dfs.append()\n",
    "\n",
    "# Kết hợp tất cả các DataFrame thành một DataFrame lớn\n",
    "total_data = pd.concat(dfs)\n",
    "\n",
    "# Sử dụng set để loại bỏ các dòng trùng lặp\n",
    "total_data[\"text\"] = total_data[\"text\"].astype(str)\n",
    "print(total_data.shape)\n",
    "total_data = pd.DataFrame(list(set(tuple(row) for row in total_data.to_records(index=False))))\n",
    "\n",
    "# Randomize the order of the rows multiple times\n",
    "total_data = total_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "total_data = total_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "total_data = total_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Lưu DataFrame kết quả vào tệp CSV\n",
    "total_data.columns = [\"file\", \"text\", \"duration\"]\n",
    "total_data.to_csv('/home/pdnguyen/fast_confomer_finetun/finetune-fast-conformer/notebooks/results_csv/demo_roi_xoa.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lọc data không cần thiết theo keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc tệp CSV vào DataFrame\n",
    "input_file_path = \"/mnt/driver/STT_data/STT_dataset/64.Metadata_t5_64_63_..._57RDC/64.Metadata_t6__exits.csv\"\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Lọc các hàng không chứa 'vlsp-2020' và '61.Augment2same_telesales' trong cột 'file'\n",
    "df_filtered = df[~(df['file'].str.contains('vlsp-2020') | df['file'].str.contains('61.Augment2same_telesales'))]\n",
    "\n",
    "# Lưu DataFrame đã được lọc vào tệp CSV mới\n",
    "output_file_path = \"/mnt/driver/STT_data/STT_dataset/64.Metadata_t5_64_63_..._57RDC/64.Metadata_t6__exits.csv\"\n",
    "df_filtered.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Tệp CSV đã được lọc và lưu thành công.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc tệp CSV vào DataFrame\n",
    "input_file_path = \"/mnt/driver/STT_data/STT_dataset/61.Augment2same_telesales/61.Augment_telesale.csv\"\n",
    "df = pd.read_csv(input_file_path)\n",
    "df_sample = df.sample(frac=0.2, random_state=1).reset_index(drop=True)\n",
    "out = \"/mnt/driver/STT_data/STT_dataset/61.Augment2same_telesales/0cham1_percent.csv\"\n",
    "df_sample.to_csv(out, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
